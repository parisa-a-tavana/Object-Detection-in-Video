{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lc3yfWPkGhJq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow ## im_show was disabled in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yURk0zysGop0"
      },
      "outputs": [],
      "source": [
        "## Global Variables\n",
        "\n",
        "VIDEO_PATH = '/content/yolo_test.mp4'\n",
        "CONFIG_FILE = '/content/yolov3.cfg'\n",
        "WEIGTS_FILE = '/content/yolov3.weights'\n",
        "CLASSES_FILE = '/content/COCO_Class_Codes.txt'\n",
        "\n",
        "SCALE = 1.0/255 ## converts color code range from 0-255 to 0-1\n",
        "SIZE = (320, 320)\n",
        "MEAN = (0,0,0)\n",
        "\n",
        "CLASSES = []\n",
        "with open(CLASSES_FILE , 'r') as f:\n",
        "  read_data = f.read().split('\\'')\n",
        "  CLASSES = [read_data[i] for i in range(len(read_data)) if i%2==1]\n",
        "\n",
        "wanted_classes_idx = [0, 2, 5] #human, car, and bus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dgEexYMdYXF6"
      },
      "outputs": [],
      "source": [
        "def find_obejct(outputs):\n",
        "\n",
        "  class_ids, confidences, boxes = [], [], []\n",
        "\n",
        "  for output in outputs:\n",
        "    \n",
        "    for detection in output:\n",
        "\n",
        "      scores = detection[5:]\n",
        "      max_score_wanted_classes_idx = np.argmax([scores[idx] for idx in wanted_classes_idx])\n",
        "      class_id = wanted_classes_idx[max_score_wanted_classes_idx]\n",
        "      confidence = scores[class_id]\n",
        "\n",
        "      if confidence > 0.5:\n",
        "        center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype(\"int\")\n",
        "        x = int(center_x - w / 2)\n",
        "        y = int(center_y - h / 2)\n",
        "        boxes.append([x, y, int(w), int(h)])\n",
        "        confidences.append(float(confidence))\n",
        "        class_ids.append(class_id)\n",
        "\n",
        "  return class_ids, confidences, boxes\n",
        "\n",
        "\n",
        "\n",
        "def show_detected_object(frame, class_ids, confidences, boxes):\n",
        "  \n",
        "  colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
        "\n",
        "  for i, box in enumerate(boxes):\n",
        "    x, y, w, h = box\n",
        "    label_and_confidence = \"{} {:.2f}\".format(CLASSES[class_ids[i]], confidences[i])\n",
        "    color = colors[i]\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "    cv2.putText(frame, label_and_confidence, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RfQ-6V1mfu3G"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNet(WEIGTS_FILE, CONFIG_FILE)\n",
        "\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "vid = cv2.VideoCapture(VIDEO_PATH)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv2.VideoWriter('output.mp4',fourcc, 5, (1280,720))\n",
        "\n",
        "while True:\n",
        "  \n",
        "  ret, frame = vid.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  height, width, _ = frame.shape\n",
        "  blob = cv2.dnn.blobFromImage(frame, SCALE, SIZE, MEAN, swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  outs = net.forward(output_layers)\n",
        "  class_ids, confidences, boxes = find_obejct(outs)\n",
        "  frame = show_detected_object(frame, class_ids, confidences, boxes)\n",
        "\n",
        "  output_video.write(frame)\n",
        "\n",
        "  if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "    break\n",
        "\n",
        "vid.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}